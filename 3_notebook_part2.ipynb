{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1LZ8HY1Y5HH0OSqmpHUkSzRE7HTzeMxQo\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MiHp58KI7c_"
      },
      "source": [
        "# Problem 3, Parts F-H: Stochastic Gradient Descent with a Larger Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBMavqB9I7dD"
      },
      "source": [
        "Use this notebook to write your code for problem 3 parts F-H by filling in the sections marked `# TODO` and running all cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "_id_dict = {\n",
        "    'sgd_data.csv': '14UPDlsLd9sn0aVOCjslCgyB3AtQoYvnZ',\n",
        "}\n",
        "\n",
        "def download_from_gdrive(file_path):\n",
        "    file_id = _id_dict[file_path]\n",
        "    \n",
        "    URL = \"https://docs.google.com/uc?export=download&confirm=1\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params={\"id\": file_id}, stream=True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = {\"id\": file_id, \"confirm\": token}\n",
        "        response = session.get(URL, params=params, stream=True)\n",
        "    save_content(response, file_path)\n",
        "\n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith(\"download_warning\"):\n",
        "            return value\n",
        "    return None\n",
        "\n",
        "\n",
        "def save_content(response, destination):\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(1024* 1024 * 100):\n",
        "            if chunk:\n",
        "                f.write(chunk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zD8uOTAbI7dE"
      },
      "outputs": [],
      "source": [
        "# Setup.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmeowyuSI7dF"
      },
      "source": [
        "## Problem 3F: Perform SGD with the new dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_Yr_uEXI7dG"
      },
      "source": [
        "For the functions below, you may re-use your code from parts 3C-E. Note that you can now modify your SGD function to return the final weight vector instead of the weights after every epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "lOqNtnhXI7dG"
      },
      "outputs": [],
      "source": [
        "def loss(X, Y, w):\n",
        "    '''\n",
        "    Calculate the squared loss function.\n",
        "    \n",
        "    Inputs:\n",
        "        X: A (N, D) shaped numpy array containing the data points.\n",
        "        Y: A (N, ) shaped numpy array containing the (float) labels of the data points.\n",
        "        w: A (D, ) shaped numpy array containing the weight vector.\n",
        "    \n",
        "    Outputs:\n",
        "        The loss evaluated with respect to X, Y, and w.\n",
        "    '''\n",
        "    \n",
        "    #==============================================\n",
        "    # TODO: Implement the SGD loss function.\n",
        "    #==============================================\n",
        "    \n",
        "    pass\n",
        "\n",
        "def gradient(x, y, w):\n",
        "    '''\n",
        "    Calculate the gradient of the loss function with respect to\n",
        "    a single point (x, y), and using weight vector w.\n",
        "    \n",
        "    Inputs:\n",
        "        x: A (D, ) shaped numpy array containing a single data point.\n",
        "        y: The float label for the data point.\n",
        "        w: A (D, ) shaped numpy array containing the weight vector.\n",
        "        \n",
        "    Output:\n",
        "        The gradient of the loss with respect to x, y, and w. \n",
        "    '''\n",
        "    \n",
        "    #==============================================\n",
        "    # TODO: Implement the gradient of the loss function.\n",
        "    #==============================================    \n",
        "    \n",
        "    pass\n",
        "\n",
        "def SGD(X, Y, w_start, eta, N_epochs):\n",
        "    '''\n",
        "    Perform SGD using dataset (X, Y), initial weight vector w_start,\n",
        "    learning rate eta, and N_epochs epochs.\n",
        "    \n",
        "    Inputs:\n",
        "        X: A (N, D) shaped numpy array containing the data points.\n",
        "        Y: A (N, ) shaped numpy array containing the (float) labels of the data points.\n",
        "        w_start:  A (D, ) shaped numpy array containing the weight vector initialization.\n",
        "        eta: The step size.\n",
        "        N_epochs: The number of epochs (iterations) to run SGD.\n",
        "        \n",
        "    Outputs:\n",
        "        w: A (D, ) shaped array containing the final weight vector.\n",
        "        losses: A (N_epochs, ) shaped array containing the losses from all iterations.\n",
        "    '''\n",
        "    \n",
        "    #==============================================\n",
        "    # TODO: Implement the SGD algorithm.\n",
        "    #==============================================    \n",
        "    \n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URle0yiaI7dI"
      },
      "source": [
        "Next, we need to load the dataset. In doing so, the following function may be helpful:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HawZHA9-I7dJ"
      },
      "outputs": [],
      "source": [
        "def load_data(filename):\n",
        "    \"\"\"\n",
        "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
        "    \n",
        "    Inputs:\n",
        "        filename: GeneratorExitiven as a string.\n",
        "    \n",
        "    Outputs:\n",
        "        Data contained in the file, returned as a numpy ndarray\n",
        "    \"\"\"\n",
        "    return np.loadtxt(filename, skiprows=1, delimiter=',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miOL66ooI7dJ"
      },
      "source": [
        "Now, load the dataset in `sgd_data.csv` and run SGD using the given parameters; print out the final weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "download_from_gdrive('sgd_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "w8zujpzQI7dK"
      },
      "outputs": [],
      "source": [
        "#==============================================\n",
        "# TODO:\n",
        "# (1) load the dataset\n",
        "# (2) run SGD using the given parameters\n",
        "# (3) print out the final weights.\n",
        "#==============================================\n",
        "\n",
        "# The following should help you get started:\n",
        "\n",
        "load_data('sgd_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrQbch5ZI7dL"
      },
      "source": [
        "## Problem 3G: Convergence of SGD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wifm5ZIMI7dL"
      },
      "source": [
        "This problem examines the convergence of SGD for different learning rates. Please implement your code in the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gV4SipwAI7dL"
      },
      "outputs": [],
      "source": [
        "#==============================================\n",
        "# TODO: create a plot showing the convergence\n",
        "# of SGD for the different learning rates.\n",
        "#=============================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vRECK4XI7dM"
      },
      "source": [
        "## Problem 3H"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCovlxnHI7dM"
      },
      "source": [
        "Provide your code for computing the least-squares analytical solution below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PW5MWI-2I7dM"
      },
      "outputs": [],
      "source": [
        "#==============================================\n",
        "# TODO: implement the least-squares\n",
        "# analytical solution.\n",
        "#=============================================="
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "include_colab_link": true,
      "name": "3_notebook_part2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
