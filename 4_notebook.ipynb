{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9T008hSrS4g"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1uhy0NrsDTe88YNa-Lb45svhl2QDy9uWW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ALpffMQqzTp"
      },
      "source": [
        "# Problem 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45Qc65tGqzTs"
      },
      "source": [
        "Use this notebook to write your code for problem 4 by filling in the sections marked `# TODO` and running all cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_id_dict = {\n",
        "    'perceptron_helper.py': '1IRQpawctlTlhuvHI1uCLTOYvQ10rrT39',\n",
        "}\n",
        "\n",
        "import requests\n",
        "\n",
        "def download_from_gdrive(file_path):\n",
        "    file_id = _id_dict[file_path]\n",
        "    URL = \"https://docs.google.com/uc?export=download&confirm=1\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params={\"id\": file_id}, stream=True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = {\"id\": file_id, \"confirm\": token}\n",
        "        response = session.get(URL, params=params, stream=True)\n",
        "    save_content(response, file_path)\n",
        "\n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith(\"download_warning\"):\n",
        "            return value\n",
        "    return None\n",
        "\n",
        "\n",
        "def save_content(response, destination):\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(1024* 1024 * 100):\n",
        "            if chunk:\n",
        "                f.write(chunk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "collapsed": true,
        "id": "C24BbGjEqzTt"
      },
      "outputs": [],
      "source": [
        "download_from_gdrive('perceptron_helper.py')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "\n",
        "from perceptron_helper import (\n",
        "    predict,\n",
        "    plot_data,\n",
        "    boundary,\n",
        "    plot_perceptron,\n",
        ")\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIkhdeZqqzTu"
      },
      "source": [
        "## Implementation of Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5973drXAqzTv"
      },
      "source": [
        "First, we will implement the perceptron algorithm. Fill in the `update_perceptron()` function so that it finds a single misclassified point and updates the weights and bias accordingly. If no point exists, the weights and bias should not change.\n",
        "\n",
        "Hint: You can use the `predict()` helper method, which labels a point 1 or -1 depending on the weights and bias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Y8NoAG9HqzTv"
      },
      "outputs": [],
      "source": [
        "def update_perceptron(X, Y, w, b):\n",
        "    \"\"\"\n",
        "    This method updates a perceptron model. Takes in the previous weights\n",
        "    and returns weights after an update, which could be nothing.\n",
        "    \n",
        "    Inputs:\n",
        "        X: A (N, D) shaped numpy array containing a single point.\n",
        "        Y: A (N, ) shaped numpy array containing the labels for the points.\n",
        "        w: A (D, ) shaped numpy array containing the weight vector.\n",
        "        b: A float containing the bias term.\n",
        "    \n",
        "    Output:\n",
        "        next_w: A (D, ) shaped numpy array containing the next weight vector\n",
        "                after updating on a single misclassified point, if one exists.\n",
        "        next_b: The next float bias term after updating on a single\n",
        "                misclassified point, if one exists.\n",
        "        misclassified: The misclassified point used to update perceptron.\n",
        "    \"\"\"\n",
        "    next_w, next_b = np.copy(w), np.copy(b)\n",
        "    misclassified = None\n",
        "    \n",
        "    #==============================================\n",
        "    # TODO: Implement update rule for perceptron.\n",
        "    #===============================================\n",
        "    \n",
        "    return next_w, next_b, misclassified"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlXK7ip4qzTw"
      },
      "source": [
        "Next you will fill in the `run_perceptron()` method. The method performs single updates on a misclassified point until convergence, or max_iter updates are made. The function will return the final weights and bias. You should use the `update_perceptron()` method you implemented above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "evL6q3TFqzTw"
      },
      "outputs": [],
      "source": [
        "def run_perceptron(X, Y, w, b, max_iter):\n",
        "    \"\"\"\n",
        "    This method runs the perceptron learning algorithm. Takes in initial weights\n",
        "    and runs max_iter update iterations. Returns final weights and bias.\n",
        "    \n",
        "    Inputs:\n",
        "        X: A (N, D) shaped numpy array containing a single point.\n",
        "        Y: A (N, ) shaped numpy array containing the labels for the points.\n",
        "        w: A (D, ) shaped numpy array containing the initial weight vector.\n",
        "        b: A float containing the initial bias term.\n",
        "        max_iter: An int for the maximum number of updates evaluated.\n",
        "        \n",
        "    Output:\n",
        "        w: A (D, ) shaped numpy array containing the final weight vector.\n",
        "        b: The final float bias term.\n",
        "    \"\"\"\n",
        "    \n",
        "    #============================================\n",
        "    # TODO: Implement perceptron update loop.\n",
        "    #=============================================\n",
        "\n",
        "    return w, b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTQaUVJkqzTx"
      },
      "source": [
        "# Problem 4A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5iZpojjqzTy"
      },
      "source": [
        "## Visualizing a Toy Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5nSahGSqzTy"
      },
      "source": [
        "We will begin by training our perceptron on a toy dataset of 3 points. The green points are labelled +1 and the red points are labelled -1. We use the helper function `plot_data()` to do so."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ybU9b-kOqzTy"
      },
      "outputs": [],
      "source": [
        "X = np.array([[ -3, -1], [0, 3], [1, -2]])\n",
        "Y = np.array([ -1, 1, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Db07hBxkqzTz"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(5,4))\n",
        "ax = fig.gca(); ax.set_xlim(-4.1, 3.1); ax.set_ylim(-3.1, 4.1)\n",
        "plot_data(X, Y, ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwzOhknIqzTz"
      },
      "source": [
        "## Running the Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCdGYyOWqzTz"
      },
      "source": [
        "Next, we will run the perceptron learning algorithm on this dataset. Update the code to show the weights and bias at each timestep and the misclassified point used in each update.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeGxFa9dqzTz"
      },
      "source": [
        "Run the below code, and fill in the corresponding table in the set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "nsaiLYGAqzT0"
      },
      "outputs": [],
      "source": [
        "# Initialize weights and bias.\n",
        "weights = np.array([0.0, 1.0])\n",
        "bias = 0.0\n",
        "\n",
        "weights, bias = run_perceptron(X, Y, weights, bias, 16)\n",
        "\n",
        "print()\n",
        "print (\"final w = %s, final b = %.1f\" % (weights, bias))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbaFhPi-qzT0"
      },
      "source": [
        "## Visualizating the Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et1FmFCfqzT0"
      },
      "source": [
        "Getting all that information in table form isn't very informative. Let us visualize what the decision boundaries are at each timestep instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Iz0K0xLqzT0"
      },
      "source": [
        "The helper functions `boundary()` and `plot_perceptron()` plot a decision boundary given a perceptron weights and bias. Note that the equation for the decision boundary is given by:\n",
        "\n",
        "$$w_1x_1 + w_2x_2 + b = 0.$$ \n",
        "\n",
        "Using some algebra, we can obtain $x_2$ from $x_1$ to plot the boundary as a line. \n",
        "\n",
        "$$x_2 = \\frac{-w_1x_1 - b}{w_2}. $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf2LwVqsqzT0"
      },
      "source": [
        "Below is a redefinition of the `run_perceptron()` method to visualize the points and decision boundaries at each timestep instead of printing.  Fill in the method using your previous `run_perceptron()` method, and the above helper methods.\n",
        "\n",
        "Hint: The axs element is a list of Axes, which are used as subplots for each timestep. You can  do the following:\n",
        "```\n",
        "ax = axs[i]\n",
        "```\n",
        "to get the plot correponding to $t = i$. You can then use ax.set_title() to title each subplot. You will want to use the `plot_data()` and `plot_perceptron()` helper methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kyorEv3cqzT1"
      },
      "outputs": [],
      "source": [
        "def run_perceptron(X, Y, w, b, axs, max_iter):\n",
        "    \"\"\"\n",
        "    This method runs the perceptron learning algorithm and plots data, weight, and bias at each timestep. \n",
        "    Takes in initial weights and runs max_iter update iterations. Returns final weights and bias.\n",
        "    \n",
        "    Inputs:\n",
        "        X: A (N, D) shaped numpy array containing a single point.\n",
        "        Y: A (N, ) shaped numpy array containing the labels for the points.\n",
        "        w: A (D, ) shaped numpy array containing the initial weight vector.\n",
        "        b: A float containing the initial bias term.\n",
        "        axs: A list of Axes that contain suplots for each timestep. \n",
        "        max_iter: An int for the maximum number of updates evaluated.\n",
        "        \n",
        "    Output:\n",
        "        The final weight and bias vectors.\n",
        "    \"\"\"\n",
        "    \n",
        "    #============================================\n",
        "    # TODO: Implement perceptron update loop.\n",
        "    #=============================================\n",
        "\n",
        "    return w, b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khI8StjwqzT1"
      },
      "source": [
        "Run the below code to get a visualization of the perceptron algorithm. The red region are areas the perceptron thinks are negative examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Kbn8QE-7qzT1"
      },
      "outputs": [],
      "source": [
        "# Initialize weights and bias.\n",
        "weights = np.array([0.0, 1.0])\n",
        "bias = 0.0\n",
        "\n",
        "f, ax_arr = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(9,8))\n",
        "axs = list(itertools.chain.from_iterable(ax_arr))\n",
        "for ax in axs:\n",
        "    ax.set_xlim(-4.1, 3.1); ax.set_ylim(-3.1, 4.1)\n",
        "\n",
        "run_perceptron(X, Y, weights, bias, axs, 4)\n",
        "\n",
        "f.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIeIOhzXqzT1"
      },
      "source": [
        "# Problem 4C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygr26jhMqzT1"
      },
      "source": [
        "## Visualize a Non-linearly Separable Dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTSnPwM-qzT1"
      },
      "source": [
        "We will now work on a dataset that cannot be linearly separated, namely one that is generated by the XOR function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GhQ4NvEQqzT2"
      },
      "outputs": [],
      "source": [
        "X = np.array([[0, 1], [1, 0], [0, 0], [1, 1]])\n",
        "Y = np.array([1, 1, -1, -1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Yp3TGvZbqzT2"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(5,4))\n",
        "ax = fig.gca(); ax.set_xlim(-0.1, 1.1); ax.set_ylim(-0.1, 1.1)\n",
        "plot_data(X, Y, ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrjnloCEqzT2"
      },
      "source": [
        "We will now run the perceptron algorithm on this dataset. We will limit the total timesteps this time, but you should see a pattern in the updates. Run the below code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qcqXP3JHqzT2"
      },
      "outputs": [],
      "source": [
        "# Initialize weights and bias.\n",
        "weights = np.array([0.0, 1.0])\n",
        "bias = 0.0\n",
        "\n",
        "f, ax_arr = plt.subplots(4, 4, sharex=True, sharey=True, figsize=(9,8))\n",
        "axs = list(itertools.chain.from_iterable(ax_arr))\n",
        "for ax in axs:\n",
        "    ax.set_xlim(-0.1, 1.1); ax.set_ylim(-0.1, 1.1)\n",
        "    \n",
        "run_perceptron(X, Y, weights, bias, axs, 16)\n",
        "\n",
        "f.tight_layout()"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "name": "4_notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
